# Instructions:
#
# label: {answer1|answer2}
#
# should be edited to read
#
# label: answer1
# OR
# label: answer2

#################################
#  NGrams                       #
#################################

# Part A
a_1_distribution: k / (k * |V|). The counts C_abc and C_ab for a new context will both be zero.
a_1_depends_on_k: The answer depends on k because if k was not there, a new context's probability would always be zero.
a_2_good_estimate: Better
a_3_pqba: k / (Cab + k * |V|)
a_4_which_context: Context (b)
a_5_which_should: Context (a)

# Part C
# c_1: include c1.png in this directory with your derivation.
c_2_which_case: b
c_2_why: Case (b) because the first term in P_kn(c|b) relies on counts and thus will be very small for (b) therefore the alpha term will need to be very large to compensate to achieve normalization. Case (a) does not need alpha to compensate because its count value is already very large. 

# Part E
e_1_average_count_per_trigram_ignoring_zero_counts: 0
e_1_average_count_per_trigram_including_zero_counts: 0
e_2_brown: {4|5}
e_2_wikipedia: {4|5}
e_3_realistic: {addk|kn|unsmoothed}

################################
# Neural Language Model        #
################################

a_1_cell_func: "h = sigmoid(h^{i}h^{-1}+W_{x} x_{i}+b_{h})" where W_{x} is the associated weight vector for the hidden cell
a_1_parameters: H*H + H*V
a_2_embedding_parameters: V
a_2_output_parameters: V
a_3_single_target_word: O(2HV + 2H^2 + H)
a_3_full_distribution_of_all_target_words: O((2HV + 2H^2 + H) * sequence_length)
a_4_with_sampled_softmax: replace V with k
a_4_with_hierarchical_softmax: Assuming hierachical softmax has the same worst case as binary search, replace V with log(V)
a_5_slowest_part: recurrent

c_1_explain_run_epoch: Your answer.

d_1_number_agreement: The probabilities are very close, but "is" wins over "are" ("are" is grammatically correct). This might be because the RNN was trained on more examples with "is" following "and the girl" than "are". There might be less examples in the training set with nouns combined by "and".
d_2_semantic_agreement: For the peanut example, the vegetable option is more plausible according to the model. This might be because there are more examples in the training data of folks commenting on their favorite vegetable. For the hungry example, the eat option is more plausible according to the model. This is correct. I would expect the 3-gram and 5-gram models to perform worse at these examples, as in both the key token ("peanuts" in the first and "hungry" in the second) are outside of the context window of 3- and 5-gram models.
d_3_JJ_order: Your answer
